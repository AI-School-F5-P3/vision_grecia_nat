{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "face_recognition_project/\n",
    "│\n",
    "├── data/                   # Directorio para datos\n",
    "│   ├── raw/                # Imágenes crudas capturadas de la cámara\n",
    "│   ├── processed/          # Imágenes preprocesadas (escaladas, recortadas, etc.)\n",
    "│   └── embeddings/         # Representaciones numéricas generadas por el modelo\n",
    "│\n",
    "├── models/                 # Directorio para modelos entrenados y checkpoints\n",
    "│   ├── face_detector/      # Modelo para detección de rostros\n",
    "│   └── face_classifier/    # Modelo para clasificación de rostros\n",
    "│\n",
    "├── scripts/                # Scripts principales\n",
    "│   ├── train.py            # Script para entrenar el modelo\n",
    "│   ├── detect_faces.py     # Script para detección de rostros\n",
    "│   └── classify_faces.py   # Script para clasificación de rostros\n",
    "│\n",
    "├── utils/                  # Funciones auxiliares\n",
    "│   ├── preprocessing.py    # Funciones para procesar imágenes\n",
    "│   ├── data_loader.py      # Funciones para cargar datos\n",
    "│   └── metrics.py          # Evaluación de precisión, velocidad, etc.\n",
    "│\n",
    "├── tests/                  # Pruebas para verificar la funcionalidad\n",
    "│   ├── test_detection.py   # Pruebas para el modelo de detección\n",
    "│   └── test_classification.py # Pruebas para el modelo de clasificación\n",
    "│\n",
    "├── requirements.txt        # Dependencias del proyecto\n",
    "├── README.md               # Descripción del proyecto\n",
    "└── main.py                 # Script principal para ejecutar el sistema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\4_F5\\024_computer_vision\\vision_grecia_nat\\env024\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "25-01-13 11:34:04 - Directory C:\\Users\\nel_n\\.deepface has been created\n",
      "25-01-13 11:34:04 - Directory C:\\Users\\nel_n\\.deepface\\weights has been created\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/face_classifier/svm_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 68\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Cargar modelo y etiquetas\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     32\u001b[0m     label_encoder\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/face_classifier/labels.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m():\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Carga el modelo preentrenado.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\4_F5\\024_computer_vision\\vision_grecia_nat\\env024\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/face_classifier/svm_model.pkl'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from deepface import DeepFace  # Puedes usar cualquier librería compatible\n",
    "\n",
    "# Ruta al modelo preentrenado\n",
    "MODEL_PATH = \"models/face_classifier/svm_model.pkl\"\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Carga el modelo preentrenado.\"\"\"\n",
    "    return joblib.load(MODEL_PATH)\n",
    "\n",
    "def detect_faces(frame):\n",
    "    \"\"\"Detecta rostros en la imagen usando Haar Cascades.\"\"\"\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "def classify_face(face_img, model, label_encoder):\n",
    "    \"\"\"Clasifica el rostro detectado.\"\"\"\n",
    "    embedding = DeepFace.represent(face_img, model_name=\"Facenet\")[0][\"embedding\"]\n",
    "    prediction = model.predict([embedding])\n",
    "    return label_encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "def main():\n",
    "    # Cargar modelo y etiquetas\n",
    "    model = load_model()\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.classes_ = np.load(\"models/face_classifier/labels.npy\", allow_pickle=True)\n",
    "    \n",
    "    # Iniciar la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detección de rostros\n",
    "        faces = detect_faces(frame)\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Clasificación del rostro\n",
    "            try:\n",
    "                name = classify_face(face_img, model, label_encoder)\n",
    "            except:\n",
    "                name = \"Desconocido\"\n",
    "            \n",
    "            # Dibujar el cuadro y el nombre\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        \n",
    "        # Mostrar el video en vivo\n",
    "        cv2.imshow(\"Reconocimiento Facial\", frame)\n",
    "\n",
    "        # Salir con 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Próximos Pasos \n",
    "Entrena el modelo de clasificación:\n",
    "Usa un dataset de imágenes de tu compañero y tú.\n",
    "Genera embeddings con una librería como DeepFace y entrena un clasificador (SVM/KNN).\n",
    "\n",
    "\n",
    "Optimiza el rendimiento:\n",
    "· Preprocesa las imágenes (escalado, normalización).\n",
    "· Usa modelos ligeros para la detección (por ejemplo, Mediapipe).\n",
    "\n",
    "Prueba y depura:\n",
    "Asegúrate de que el sistema funcione en diferentes condiciones de iluminación.\n",
    "Agrega pruebas unitarias para cada componente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
